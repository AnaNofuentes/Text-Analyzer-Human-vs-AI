{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerias\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler # for standardization us\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga del dataframe de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "data = pd.read_csv(\"example_reduced.csv\") #data set reducido de prueba SIN filtrar por len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49999 entries, 0 to 49998\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   text          49999 non-null  object\n",
      " 1   class         49999 non-null  int64 \n",
      " 2   len_text      49999 non-null  int64 \n",
      " 3   text_cleaned  49999 non-null  object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Division de X e y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"text_cleaned\"]\n",
    "y = data[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = joblib.load('vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vect = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 4533215 stored elements and shape (49999, 404235)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "# 1. Inicializa el escalador MaxAbsScaler (funciona bien con datos esparsos)\n",
    "scaler = MaxAbsScaler()\n",
    "\n",
    "# 2. Aplica el escalador directamente a la matriz esparsa sin convertirla\n",
    "X_normalized = scaler.fit_transform(text_vect)  # No usamos .toarray() para evitar el MemoryError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized = joblib.load('standarizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = standardized.transform(text_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prueba del modelo Xgboost con el dataframe de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo desde el archivo .pkl\n",
    "xgboost_model_loaded = joblib.load('xgboost_model_correct.pkl')\n",
    "y_pred_prueba = xgboost_model_loaded.predict(X_scaled)\n",
    "# Evaluación con etiquetas verdaderas\n",
    "y_true_prueba = data['class']  # Obtener las etiquetas verdaderas\n",
    "accuracy_prueba = accuracy_score(y_true_prueba, y_pred_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo en el dataframe de prueba: 0.6155723114462289\n",
      "\n",
      "Informe de clasificación para el dataframe de prueba:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.81      0.68     25112\n",
      "           1       0.69      0.42      0.52     24887\n",
      "\n",
      "    accuracy                           0.62     49999\n",
      "   macro avg       0.64      0.61      0.60     49999\n",
      "weighted avg       0.64      0.62      0.60     49999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Precisión del modelo en el dataframe de prueba:\", accuracy_prueba)\n",
    "print(\"\\nInforme de clasificación para el dataframe de prueba:\\n\", classification_report(y_true_prueba, y_pred_prueba))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
